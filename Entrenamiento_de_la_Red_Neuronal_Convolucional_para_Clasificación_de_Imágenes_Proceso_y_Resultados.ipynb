{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOh6V/ouhj+U/EJwoPXTirD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlvingEj/monitoreo_control_arvenses/blob/main/Entrenamiento_de_la_Red_Neuronal_Convolucional_para_Clasificaci%C3%B3n_de_Im%C3%A1genes_Proceso_y_Resultados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Clasificación de Hojas de Frutas con Redes Neuronales Convolucionales y Generación de Informe PDF\"**\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HDD3yOW8-c1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar paquetes necesarios\n",
        "\n",
        "#Permite la generación de documentos PDF de manera flexible.\n",
        "!pip install reportlab\n",
        "#proporciona información sobre zonas horarias y operaciones con fechas y horas.\n",
        "!pip install pytz"
      ],
      "metadata": {
        "id": "FoUf4zZg-cVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manejo de archivos y sistema operativo\n",
        "import os\n",
        "\n",
        "# Manejo de archivos zip\n",
        "import zipfile\n",
        "\n",
        "# Subida y manejo de archivos en Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Manejo de imágenes\n",
        "from PIL import Image\n",
        "\n",
        "# Manejo de tiempo y zona horaria\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Librerías para creación de gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# TensorFlow y Keras para la creación y entrenamiento de modelos de redes neuronales\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Librerías para la generación de PDFs\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import inch"
      ],
      "metadata": {
        "id": "nSvBqrpW_Y6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para subir y descomprimir archivo zip\n",
        "def subir_y_descomprimir_zip():\n",
        "    # Subir archivo ZIP desde el entorno de Google Colab\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        # Obtener el nombre del archivo ZIP subido\n",
        "        nombre_archivo_zip = list(uploaded.keys())[0]\n",
        "\n",
        "        try:\n",
        "            # Descomprimir el archivo ZIP en el directorio 'dataset'\n",
        "            with zipfile.ZipFile(nombre_archivo_zip, 'r') as zip_ref:\n",
        "                zip_ref.extractall('dataset')\n",
        "            print(\"Archivo zip descomprimido correctamente\")\n",
        "        except zipfile.BadZipFile:\n",
        "            # Manejar el error si el archivo no es un ZIP válido\n",
        "            print(\"Error: El archivo subido no es un archivo zip válido.\")\n",
        "    else:\n",
        "        # Mensaje de error si no se subió ningún archivo\n",
        "        print(\"Error: No se subió ningún archivo zip.\")\n",
        "\n",
        "# Llamada a la función para subir y descomprimir el archivo\n",
        "subir_y_descomprimir_zip()"
      ],
      "metadata": {
        "id": "t5WvpgUEA1Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para verificar la estructura de directorios\n",
        "def verificar_estructura_directorios():\n",
        "    print(\"Contenido de la carpeta 'dataset':\")\n",
        "    print(os.listdir('dataset'))\n",
        "\n",
        "    print(\"Contenido de la carpeta 'dataset/dataset/Manzana_Sana':\")\n",
        "    print(os.listdir('dataset/dataset/Manzana_Sana'))\n",
        "    print(\"Contenido de la carpeta 'dataset/dataset/Uva_Sana':\")\n",
        "    print(os.listdir('dataset/dataset/Uva_Sana'))\n",
        "\n",
        "# Llamada a la función para verificar la estructura de directorios\n",
        "verificar_estructura_directorios()"
      ],
      "metadata": {
        "id": "vw92C86aA1Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar generadores de imágenes\n",
        "def configurar_generadores_imagenes():\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    generador_entrenamiento = datagen.flow_from_directory(\n",
        "        'dataset/dataset',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    generador_validacion = datagen.flow_from_directory(\n",
        "        'dataset/dataset',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    print(f\"Se encontraron {generador_entrenamiento.samples} imágenes pertenecientes a {generador_entrenamiento.num_classes} clases para entrenamiento.\")\n",
        "    print(f\"Se encontraron {generador_validacion.samples} imágenes pertenecientes a {generador_validacion.num_classes} clases para validación.\")\n",
        "\n",
        "    return generador_entrenamiento, generador_validacion\n",
        "\n",
        "# Llamada a la función para configurar los generadores de imágenes\n",
        "generador_entrenamiento, generador_validacion = configurar_generadores_imagenes()\n"
      ],
      "metadata": {
        "id": "6Yia-2lXBXfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir y compilar el modelo\n",
        "def construir_y_compilar_modelo():\n",
        "    modelo = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    modelo.compile(loss='binary_crossentropy',\n",
        "                   optimizer='adam',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "    modelo.summary()\n",
        "    return modelo\n",
        "\n",
        "# Llamada a la función para construir y compilar el modelo\n",
        "modelo = construir_y_compilar_modelo()"
      ],
      "metadata": {
        "id": "bzteCIk7BXc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "historial = modelo.fit(\n",
        "    generador_entrenamiento,\n",
        "    epochs=25,\n",
        "    validation_data=generador_validacion\n",
        ")\n"
      ],
      "metadata": {
        "id": "u-PyNHnwETVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar métricas de entrenamiento\n",
        "def graficar_metricas_entrenamiento(historial):\n",
        "    acc = historial.history['accuracy']\n",
        "    val_acc = historial.history['val_accuracy']\n",
        "    loss = historial.history['loss']\n",
        "    val_loss = historial.history['val_loss']\n",
        "\n",
        "    epocas = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epocas, acc, 'r', label='Precisión de entrenamiento')\n",
        "    plt.plot(epocas, val_acc, 'b', label='Precisión de validación')\n",
        "    plt.title('Precisión de entrenamiento y validación')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epocas, loss, 'r', label='Pérdida de entrenamiento')\n",
        "    plt.plot(epocas, val_loss, 'b', label='Pérdida de validación')\n",
        "    plt.title('Pérdida de entrenamiento y validación')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "graficar_metricas_entrenamiento(historial)"
      ],
      "metadata": {
        "id": "gqUgiyLJBdp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para predecir y mostrar imágenes, además de guardar la imagen procesada y la predicción\n",
        "def predecir_guardar_y_mostrar_imagen(ruta_imagen, modelo, directorio_salida):\n",
        "    try:\n",
        "        img = Image.open(ruta_imagen)\n",
        "        img_redimensionada = img.resize((150, 150))\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img_redimensionada)\n",
        "        img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "        prediccion = modelo.predict(img_array)\n",
        "        etiqueta_clase = \"Hoja de Uva\" if prediccion[0] > 0.5 else \"Hoja de Manzana\"\n",
        "\n",
        "        print(f\"{os.path.basename(ruta_imagen)}: Predicción - {etiqueta_clase}\")\n",
        "\n",
        "        ruta_guardar_imagen = f\"{directorio_salida}/{os.path.basename(ruta_imagen)}\"\n",
        "        img_redimensionada.save(ruta_guardar_imagen)\n",
        "\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(img_redimensionada)\n",
        "        plt.title(f\"Predicción: {etiqueta_clase}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        return ruta_guardar_imagen, etiqueta_clase\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {ruta_imagen}: {e}\")\n",
        "        return ruta_imagen, \"Error\""
      ],
      "metadata": {
        "id": "HEcMwijyBdm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar imágenes y predecir\n",
        "subidos = files.upload()\n",
        "directorio_salida = 'imagenes_procesadas'\n",
        "os.makedirs(directorio_salida, exist_ok=True)\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for nombre_archivo in subidos.keys():\n",
        "    ruta_imagen = nombre_archivo\n",
        "    ruta_guardar_imagen, prediccion = predecir_guardar_y_mostrar_imagen(ruta_imagen, modelo, directorio_salida)\n",
        "    resultados.append((ruta_guardar_imagen, prediccion))"
      ],
      "metadata": {
        "id": "KRwEM4CgE6AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar informe en PDF\n",
        "def generar_informe_pdf(resultados, ruta_pdf='Informe_Predicciones.pdf'):\n",
        "    c = canvas.Canvas(ruta_pdf, pagesize=letter)\n",
        "    ancho, alto = letter\n",
        "\n",
        "    margen = 50\n",
        "    ancho_imagen = 2 * inch\n",
        "    alto_imagen = 2 * inch\n",
        "    altura_linea = 20\n",
        "\n",
        "    zona_horaria_local = pytz.timezone('America/Bogota')\n",
        "    hora_local = datetime.now(zona_horaria_local).strftime('%d-%m-%y %H:%M:%S')\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(margen, alto - margen + 20, \"Informe de Predicciones\")\n",
        "    c.setFont(\"Helvetica\", 10)\n",
        "    c.drawString(margen, alto - margen, f\"Fecha y Hora: {hora_local}\")\n",
        "\n",
        "    posicion_y = alto - margen - 40\n",
        "\n",
        "    for ruta_guardar_imagen, prediccion in resultados:\n",
        "        if posicion_y - (alto_imagen + altura_linea) < margen:\n",
        "            c.showPage()\n",
        "            c.setFont(\"Helvetica-Bold\", 12)\n",
        "            c.drawString(margen, alto - margen + 20, \"Informe de Predicciones\")\n",
        "            c.setFont(\"Helvetica\", 10)\n",
        "            c.drawString(margen, alto - margen, f\"Fecha y Hora: {hora_local}\")\n",
        "            posicion_y = alto - margen - 40\n",
        "\n",
        "        c.drawString(margen, posicion_y, f\"{os.path.basename(ruta_guardar_imagen)}: Predicción - {prediccion}\")\n",
        "        posicion_y -= altura_linea\n",
        "\n",
        "        c.drawImage(ruta_guardar_imagen, margen, posicion_y - alto_imagen, width=ancho_imagen, height=alto_imagen)\n",
        "        posicion_y -= alto_imagen + altura_linea\n",
        "\n",
        "    c.save()\n",
        "\n",
        "    print(\"Informe PDF generado como 'Informe_Predicciones.pdf'\")\n",
        "    files.download(ruta_pdf)\n",
        "\n",
        "generar_informe_pdf(resultados)"
      ],
      "metadata": {
        "id": "imXkotLIBdjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###no borrar - imagen ecualizada"
      ],
      "metadata": {
        "id": "Xtf88uUKA1DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1frIXE9nfc1T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Cargar la imagen en escala de grises\n",
        "# Usa la opción de Google Colab para subir archivos o carga una imagen desde una URL\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    image_path = filename\n",
        "\n",
        "# Leer la imagen en escala de grises\n",
        "imagen_original = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Aplicar ecualización de histograma\n",
        "imagen_ecualizada = cv2.equalizeHist(imagen_original)\n",
        "\n",
        "# Mostrar imagen original y ecualizada usando cv2_imshow\n",
        "print(\"Imagen Original\")\n",
        "cv2_imshow(imagen_original)\n",
        "\n",
        "print(\"Imagen Ecualizada\")\n",
        "cv2_imshow(imagen_ecualizada)\n",
        "\n",
        "# Guardar la imagen ecualizada\n",
        "cv2.imwrite('imagen_ecualizada.jpg', imagen_ecualizada)\n"
      ]
    }
  ]
}